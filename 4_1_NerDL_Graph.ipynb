{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.1_NerDL_Graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/spark-nlp-new/blob/main/4_1_NerDL_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v9klEY_nSoK"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/4.1_NerDL_Graph.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88IkXOy8nUC3"
      },
      "source": [
        "# Graph Generation for NerDL Model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXEaePmbnRq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd6501f-7d2b-46df-b8c6-2c25923e8544"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/create_graph.py\n",
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/dataset_encoder.py\n",
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/ner_model.py\n",
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/ner_model_saver.py\n",
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/sentence_grouper.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-27 12:14:44--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/create_graph.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1545 (1.5K) [text/plain]\n",
            "Saving to: ‘create_graph.py’\n",
            "\n",
            "\rcreate_graph.py       0%[                    ]       0  --.-KB/s               \rcreate_graph.py     100%[===================>]   1.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-27 12:14:44 (32.0 MB/s) - ‘create_graph.py’ saved [1545/1545]\n",
            "\n",
            "--2022-04-27 12:14:44--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/dataset_encoder.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2543 (2.5K) [text/plain]\n",
            "Saving to: ‘dataset_encoder.py’\n",
            "\n",
            "dataset_encoder.py  100%[===================>]   2.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-27 12:14:44 (36.3 MB/s) - ‘dataset_encoder.py’ saved [2543/2543]\n",
            "\n",
            "--2022-04-27 12:14:44--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/ner_model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21853 (21K) [text/plain]\n",
            "Saving to: ‘ner_model.py’\n",
            "\n",
            "ner_model.py        100%[===================>]  21.34K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-04-27 12:14:44 (5.30 MB/s) - ‘ner_model.py’ saved [21853/21853]\n",
            "\n",
            "--2022-04-27 12:14:45--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/ner_model_saver.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2484 (2.4K) [text/plain]\n",
            "Saving to: ‘ner_model_saver.py’\n",
            "\n",
            "ner_model_saver.py  100%[===================>]   2.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-27 12:14:45 (51.4 MB/s) - ‘ner_model_saver.py’ saved [2484/2484]\n",
            "\n",
            "--2022-04-27 12:14:45--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/sentence_grouper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 953 [text/plain]\n",
            "Saving to: ‘sentence_grouper.py’\n",
            "\n",
            "sentence_grouper.py 100%[===================>]     953  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-27 12:14:45 (43.8 MB/s) - ‘sentence_grouper.py’ saved [953/953]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.15"
      ],
      "metadata": {
        "id": "4WTIli4vLeBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3faa8079-5a1b-4539-ca73-dd68d6f77cc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypu-r4GZj8r0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53f717e-d064-4661-feec-baa462bb4ade"
      },
      "source": [
        "import create_graph\n",
        "\n",
        "ntags = 19 # number of labels\n",
        "embeddings_dim = 100\n",
        "nchars = 100\n",
        "\n",
        "create_graph.create_graph(ntags, embeddings_dim, nchars)\n",
        "\n",
        "# then put your graph file (pb) under a folder and set it with .setGraphFolder('folder') in NerDLApproach "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.4-tf\n",
            "Spark NLP is compiled with TensorFlow 1.15.0, Please use such version.\n",
            "Current TensorFlow version:  1.15.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ner_model.py:217: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(self._word_embeddings_added or self._char_cnn_added or self._char_bilstm_added,\n",
            "/content/ner_model.py:249: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(self._context_added,\n",
            "/content/ner_model.py:295: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(self._inference_added,\n",
            "/content/ner_model.py:391: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(self._training_added, \"Add training layer by method add_training_op before running training\")\n"
          ]
        }
      ]
    }
  ]
}